{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5cd6b76",
   "metadata": {},
   "source": [
    "# BERT实现网购评论的对象分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49384fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_inline import backend_inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer,BertModel\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd2cb28",
   "metadata": {},
   "source": [
    "## 数据读取与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2f5e6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat  label                                             review\n",
       "0  书籍      1  ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...\n",
       "1  书籍      1  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...\n",
       "2  书籍      1  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...\n",
       "3  书籍      1  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...\n",
       "4  书籍      1  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"online_shopping_10_cats.csv\")[:60000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a483e0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'书籍': 0,\n",
       " '平板': 1,\n",
       " '手机': 2,\n",
       " '水果': 3,\n",
       " '洗发水': 4,\n",
       " '热水器': 5,\n",
       " '蒙牛': 6,\n",
       " '衣服': 7,\n",
       " '计算机': 8,\n",
       " '酒店': 9}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构建类别与编号的转换字典，并将类别转成编号\n",
    "class2idx ={'书籍':0, '平板':1, '手机':2, '水果':3, '洗发水':4, '热水器':5, '蒙牛':6, '衣服':7, '计算机':8, '酒店':9}\n",
    "idx2class = {idx:class_ for class_,idx in class2idx.items()}\n",
    "class_idx =[class2idx[calss_] for calss_ in df['cat'].values]\n",
    "class2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b03db9",
   "metadata": {},
   "source": [
    "## BERT微调实现网购评论的对象分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a18a2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用torch.utils.data.Dataset定义数据集类打包句子和标签\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, x,y):\n",
    "        self.dataset_x = x\n",
    "        self.dataset_y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_x)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        text = self.dataset_x[i]\n",
    "        label = self.dataset_y[i]\n",
    "\n",
    "        return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c021c50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set长度为:48000\n",
      "valid_set长度为:12000\n"
     ]
    }
   ],
   "source": [
    "#划分训练集验证集并打包句子和标签\n",
    "train_x,valid_x,train_y,valid_y= train_test_split(df['review'].values,class_idx, random_state=22,test_size=0.2)\n",
    "train_set = Dataset(train_x,train_y);valid_set = Dataset(valid_x,valid_y)\n",
    "print(f'train_set长度为:{len(train_set)}')\n",
    "print(f'valid_set长度为:{len(valid_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07d9ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载字典和分词工具\n",
    "token = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "#定义数据加载器句子和标签编码方式函数\n",
    "def collate_fn(data):\n",
    "    sents = [i[0] for i in data]\n",
    "    labels = [i[1] for i in data]\n",
    "\n",
    "    #编码\n",
    "    data = token.batch_encode_plus(batch_text_or_text_pairs=sents,\n",
    "                                   truncation=True,\n",
    "                                   padding='max_length',\n",
    "                                   max_length=200,\n",
    "                                   return_tensors='pt',\n",
    "                                   return_length=True)\n",
    "\n",
    "    #input_ids:编码之后的数字\n",
    "    #attention_mask:是补零的位置是0,其他位置是1\n",
    "    input_ids = data['input_ids']\n",
    "    attention_mask = data['attention_mask']\n",
    "    token_type_ids = data['token_type_ids']\n",
    "    labels = torch.LongTensor(labels)\n",
    "\n",
    "    #print(data['length'], data['length'].max())\n",
    "\n",
    "    return input_ids, attention_mask, token_type_ids, labels\n",
    "\n",
    "\n",
    "#使用DataLoader封装训练集和验证集\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "                                     batch_size=256,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_set,\n",
    "                                     batch_size=256,\n",
    "                                     collate_fn=collate_fn,\n",
    "                                     shuffle=True,\n",
    "                                     drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4293bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#加载预训练模型\n",
    "pretrained = BertModel.from_pretrained('bert-base-chinese')\n",
    "\n",
    "#不训练最后一个全连接层以外的所有层,不需要计算梯度\n",
    "for param in pretrained.parameters():\n",
    "    param.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58e72ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义下游任务模型用于网购评论的对象分类任务\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = torch.nn.Linear(768, 10)#最后一个全连接层的前一层的输出维度为768\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        with torch.no_grad():\n",
    "            out = pretrained(input_ids=input_ids,\n",
    "                       attention_mask=attention_mask,\n",
    "                       token_type_ids=token_type_ids)\n",
    "\n",
    "        output = self.fc(out.last_hidden_state[:, 0])#取出[cls]用于分类\n",
    "        return output\n",
    "#实例化下游任务模型\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39716fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设定画图配置\n",
    "def use_svg_display():\n",
    "    \"\"\"Use the svg format to display a plot in Jupyter.\n",
    "\n",
    "    Defined in :numref:`sec_calculus`\"\"\"\n",
    "    backend_inline.set_matplotlib_formats('svg')\n",
    "def set_figsize(figsize=(3.5, 2.5)):\n",
    "    \"\"\"Set the figure size for matplotlib.\n",
    "\n",
    "    Defined in :numref:`sec_calculus`\"\"\"\n",
    "    use_svg_display()\n",
    "    plt.rcParams['figure.figsize'] = figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ebd46a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练类用于训练和验证并实现绘制训练集和验证损失与准确率曲线保存验证效果最好的模型\n",
    "class Train:\n",
    "    def __init__(self,max_epochs,loss_function,optimizer,model,device ='cpu'):\n",
    "        self.max_epochs = max_epochs\n",
    "        self.device = device\n",
    "        self.loss_function = loss_function\n",
    "        self.optimizer = optimizer\n",
    "        self.model = model.to(device)\n",
    "    def start_train(self,trainloader,validloader = None,val_idx = None):\n",
    "        self.trainloader = trainloader\n",
    "        self.validloader = validloader\n",
    "        self.max_iter = len(trainloader)\n",
    "        self.loss_train_list = []\n",
    "        self.loss_valid_list = []\n",
    "        self.accurary_rate_train = []\n",
    "        self.accurary_rate_valid = []\n",
    "        if val_idx != None:\n",
    "            self.max_valid_num = int(self.max_iter / val_idx)\n",
    "            self.val_idx = val_idx\n",
    "        if isinstance(self.model, nn.Module):\n",
    "            self.model.train()\n",
    "        print('Start Training!')\n",
    "        for epoch in range(self.max_epochs):\n",
    "            self.model.train()\n",
    "            train_total_num = 0\n",
    "            train_accuracy_num = 0\n",
    "            best_valid_accuracy = 0\n",
    "            for idx,(input_ids, attention_mask, token_type_ids,labels) in enumerate (self.trainloader):\n",
    "                train_total_num += input_ids.shape[0]\n",
    "                input_ids = input_ids.to(self.device)\n",
    "                attention_mask = attention_mask.to(self.device)\n",
    "                token_type_ids = token_type_ids.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                t_hat = self.model(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "                loss_ = self.loss_function(t_hat, labels)\n",
    "                train_accuracy_num += (t_hat.argmax(dim=1) == labels).sum().item()\n",
    "                self.optimizer.zero_grad()\n",
    "                loss_.backward()\n",
    "                self.optimizer.step()\n",
    "            loss = loss_.item()\n",
    "            accurary_rate = round(train_accuracy_num/train_total_num,4)\n",
    "            self.loss_train_list.append(loss)\n",
    "            self.accurary_rate_train.append(accurary_rate)\n",
    "            print('Train_set Step [{}/{}] loss: {}, acc: {}'.format(idx+1, self.max_iter, loss, accurary_rate))\n",
    "            if (epoch+1) % self.val_idx == 0:\n",
    "                valid_num = int((epoch+1) / self.val_idx)\n",
    "                if isinstance(self.model, nn.Module):\n",
    "                    self.model.eval()\n",
    "                with torch.no_grad():\n",
    "                    valid_total_num = 0\n",
    "                    valid_accuracy_num = 0\n",
    "                    print('Start Validation!')\n",
    "                    for idx, (input_ids, attention_mask, token_type_ids,labels) in enumerate(self.validloader):\n",
    "                        valid_total_num += input_ids.shape[0]\n",
    "                        input_ids = input_ids.to(self.device)\n",
    "                        attention_mask = attention_mask.to(self.device)\n",
    "                        token_type_ids = token_type_ids.to(self.device)\n",
    "                        labels = labels.to(self.device)\n",
    "                        t_hat = self.model(input_ids=input_ids,attention_mask=attention_mask,token_type_ids=token_type_ids)\n",
    "                        valid_accuracy_num += (t_hat.argmax(dim=1) == labels).sum().item()\n",
    "                        loss_ = self.loss_function(t_hat, labels)\n",
    "                        loss = loss_.item()\n",
    "                        self.loss_valid_list.append(loss)\n",
    "                        accurary_rate = round(valid_accuracy_num / valid_total_num, 4)\n",
    "                    self.accurary_rate_valid.append(accurary_rate)\n",
    "                    print('Valid_set Step [{}/{}] loss: {}, acc: {}'.format(valid_num, self.max_valid_num, loss, accurary_rate))\n",
    "                    print('Stop Validation!')\n",
    "                    if accurary_rate > best_valid_accuracy:\n",
    "                        best_valid_accuracy = accurary_rate\n",
    "                        torch.save(self.model, 'Bert_best.pth')\n",
    "                    print('best_model has been saved!')\n",
    "    def show_loss_acc_value(self):\n",
    "        n_train_loss_value = len(self.loss_train_list)\n",
    "        n_accurary_rate_train = len(self.accurary_rate_train)\n",
    "        set_figsize(figsize=(4, 3))\n",
    "        plt.plot(list(range(n_accurary_rate_train)),self.accurary_rate_train,'r-',linewidth = 1,label = 'Train_acc')\n",
    "        plt.plot(list(range(n_train_loss_value)), self.loss_train_list, 'b-', linewidth=1, label='Train_loss')\n",
    "        if self.loss_valid_list != []:\n",
    "            n_valid_loss_value = len(self.loss_valid_list)\n",
    "            n_accurary_rate_valid = len(self.accurary_rate_valid)\n",
    "            plt.plot(list(range(n_accurary_rate_valid)), self.accurary_rate_valid, 'y-', linewidth=1, label='Valid_acc')\n",
    "            plt.plot(list(range(n_valid_loss_value)), self.loss_valid_list, 'g-', linewidth=1, label='Valid_loss')\n",
    "        plt.title('loss_acc_curve')\n",
    "        plt.xlabel('train_iter_steps')\n",
    "        plt.ylabel('loss_acc')\n",
    "        plt.legend()\n",
    "        plt.ylim(0, 1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1130cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义最大迭代次数、优化器、损失函数、设备、训练器并将模型转到相应的设备上\n",
    "max_epochs = 5\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device(0) if torch.cuda.is_available() else torch.device('cpu')\n",
    "model = model.to(device)\n",
    "pretrained = pretrained.to(device)\n",
    "train = Train(max_epochs,loss_function,optimizer,model,device =device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "506fef67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8796\\922191302.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#开始训练训练及验证并保存验证效果最好的模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidloader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8796\\3356051160.py\u001b[0m in \u001b[0;36mstart_train\u001b[1;34m(self, trainloader, validloader, val_idx)\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mt_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mloss_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                 \u001b[0mtrain_accuracy_num\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0mloss_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#开始训练训练及验证并保存验证效果最好的模型\n",
    "train.start_train(trainloader = train_loader,validloader=valid_loader,val_idx = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75877d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.show_loss_acc_value()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
