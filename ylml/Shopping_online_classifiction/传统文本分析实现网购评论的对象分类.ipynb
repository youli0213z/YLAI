{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb94c14",
   "metadata": {},
   "source": [
    "# 传统文本分析实现网购评论的对象分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b880f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import f1_score,accuracy_score,recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bb7970",
   "metadata": {},
   "source": [
    "## 数据读取与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66cf9699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat  label                                             review\n",
       "0  书籍      1  ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...\n",
       "1  书籍      1  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...\n",
       "2  书籍      1  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...\n",
       "3  书籍      1  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...\n",
       "4  书籍      1  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"online_shopping_10_cats.csv\")[:60000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e717153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\23176\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.606 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "      <th>chinese_corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...</td>\n",
       "      <td>[做, 父母, 一定, 要, 有, 刘墉, 这样, 的, 心态, 不断, 地, 学习, 不断...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...</td>\n",
       "      <td>[作者, 真有, 英国人, 严谨, 的, 风格, 提出, 观点, 进行, 论述, 论证, 尽...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...</td>\n",
       "      <td>[作者, 长篇大论, 借用, 详细, 报告, 数据处理, 工作, 和, 计算结果, 支持, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...</td>\n",
       "      <td>[作者, 在, 战, 几时, 之前, 用, 了, 拥抱, 令人, 叫绝, 日本, 如果, 没...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>书籍</td>\n",
       "      <td>1</td>\n",
       "      <td>作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...</td>\n",
       "      <td>[作者, 在, 少年, 时即, 喜, 阅读, 能, 看出, 他, 精读, 了, 无数, 经典...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat  label                                             review  \\\n",
       "0  书籍      1  ﻿做父母一定要有刘墉这样的心态，不断地学习，不断地进步，不断地给自己补充新鲜血液，让自己保持...   \n",
       "1  书籍      1  作者真有英国人严谨的风格，提出观点、进行论述论证，尽管本人对物理学了解不深，但是仍然能感受到...   \n",
       "2  书籍      1  作者长篇大论借用详细报告数据处理工作和计算结果支持其新观点。为什么荷兰曾经县有欧洲最高的生产...   \n",
       "3  书籍      1  作者在战几时之前用了＂拥抱＂令人叫绝．日本如果没有战败，就有会有美军的占领，没胡官僚主义的延...   \n",
       "4  书籍      1  作者在少年时即喜阅读，能看出他精读了无数经典，因而他有一个庞大的内心世界。他的作品最难能可贵...   \n",
       "\n",
       "                                      chinese_corpus  \n",
       "0  [做, 父母, 一定, 要, 有, 刘墉, 这样, 的, 心态, 不断, 地, 学习, 不断...  \n",
       "1  [作者, 真有, 英国人, 严谨, 的, 风格, 提出, 观点, 进行, 论述, 论证, 尽...  \n",
       "2  [作者, 长篇大论, 借用, 详细, 报告, 数据处理, 工作, 和, 计算结果, 支持, ...  \n",
       "3  [作者, 在, 战, 几时, 之前, 用, 了, 拥抱, 令人, 叫绝, 日本, 如果, 没...  \n",
       "4  [作者, 在, 少年, 时即, 喜, 阅读, 能, 看出, 他, 精读, 了, 无数, 经典...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用re正则提取中文并用jieba分词提取词语语料\n",
    "extract_chinese = re.compile(r'[\\u4e00-\\u9fa5]+')\n",
    "chinese_corpus_raw = df['review'].tolist()\n",
    "chinese_corpus_raw\n",
    "df['chinese_corpus']=[jieba.lcut(\"\".join(extract_chinese.findall(str(corpus)))) for corpus in chinese_corpus_raw]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f09c643f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['做',\n",
       " '父母',\n",
       " '一定',\n",
       " '要',\n",
       " '有',\n",
       " '刘墉',\n",
       " '这样',\n",
       " '的',\n",
       " '心态',\n",
       " '不断',\n",
       " '地',\n",
       " '学习',\n",
       " '不断',\n",
       " '地',\n",
       " '进步',\n",
       " '不断',\n",
       " '地',\n",
       " '给',\n",
       " '自己',\n",
       " '补充',\n",
       " '新鲜血液',\n",
       " '让',\n",
       " '自己',\n",
       " '保持',\n",
       " '一颗',\n",
       " '年轻',\n",
       " '的',\n",
       " '心',\n",
       " '我',\n",
       " '想',\n",
       " '这',\n",
       " '是',\n",
       " '他',\n",
       " '能',\n",
       " '很',\n",
       " '好',\n",
       " '的',\n",
       " '和',\n",
       " '孩子',\n",
       " '沟通',\n",
       " '的',\n",
       " '一个',\n",
       " '重要',\n",
       " '因素',\n",
       " '读',\n",
       " '刘墉',\n",
       " '的',\n",
       " '文章',\n",
       " '总能',\n",
       " '让',\n",
       " '我',\n",
       " '看到',\n",
       " '一个',\n",
       " '快乐',\n",
       " '的',\n",
       " '平易近人',\n",
       " '的',\n",
       " '父亲',\n",
       " '他',\n",
       " '始终',\n",
       " '站',\n",
       " '在',\n",
       " '和',\n",
       " '孩子',\n",
       " '同样',\n",
       " '的',\n",
       " '高度',\n",
       " '给',\n",
       " '孩子',\n",
       " '创造',\n",
       " '着',\n",
       " '一个',\n",
       " '充满',\n",
       " '爱',\n",
       " '和',\n",
       " '自由',\n",
       " '的',\n",
       " '生活',\n",
       " '环境',\n",
       " '很',\n",
       " '喜欢',\n",
       " '刘墉',\n",
       " '在',\n",
       " '字里行间',\n",
       " '流露出',\n",
       " '的',\n",
       " '做',\n",
       " '父母',\n",
       " '的',\n",
       " '那种',\n",
       " '小',\n",
       " '狡黠',\n",
       " '让',\n",
       " '人',\n",
       " '总是',\n",
       " '忍俊不禁',\n",
       " '父母',\n",
       " '和',\n",
       " '子女',\n",
       " '之间',\n",
       " '有时候',\n",
       " '也',\n",
       " '是',\n",
       " '一种',\n",
       " '战斗',\n",
       " '武力',\n",
       " '争斗',\n",
       " '过于',\n",
       " '低级',\n",
       " '了',\n",
       " '智力',\n",
       " '较量',\n",
       " '才',\n",
       " '更',\n",
       " '有',\n",
       " '趣味',\n",
       " '所以',\n",
       " '做',\n",
       " '父母',\n",
       " '的',\n",
       " '得',\n",
       " '加把劲',\n",
       " '了',\n",
       " '老',\n",
       " '思想',\n",
       " '老',\n",
       " '观念',\n",
       " '注定',\n",
       " '会',\n",
       " '一败涂地',\n",
       " '生命不息',\n",
       " '学习',\n",
       " '不止',\n",
       " '家庭教育',\n",
       " '真的',\n",
       " '是',\n",
       " '乐在其中']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将每条评论分词后整合到一个列表中，将每个词用空格隔开放入一个列表中\n",
    "words_list = []\n",
    "corpus = []\n",
    "for corpu in df['chinese_corpus'].tolist():\n",
    "    words_list.append(corpu)\n",
    "    corpus.append(' '.join(corpu))\n",
    "words_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5926544d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['做 父母 一定 要 有 刘墉 这样 的 心态 不断 地 学习 不断 地 进步 不断 地 给 自己 补充 新鲜血液 让 自己 保持 一颗 年轻 的 心 我 想 这 是 他 能 很 好 的 和 孩子 沟通 的 一个 重要 因素 读 刘墉 的 文章 总能 让 我 看到 一个 快乐 的 平易近人 的 父亲 他 始终 站 在 和 孩子 同样 的 高度 给 孩子 创造 着 一个 充满 爱 和 自由 的 生活 环境 很 喜欢 刘墉 在 字里行间 流露出 的 做 父母 的 那种 小 狡黠 让 人 总是 忍俊不禁 父母 和 子女 之间 有时候 也 是 一种 战斗 武力 争斗 过于 低级 了 智力 较量 才 更 有 趣味 所以 做 父母 的 得 加把劲 了 老 思想 老 观念 注定 会 一败涂地 生命不息 学习 不止 家庭教育 真的 是 乐在其中',\n",
       " '作者 真有 英国人 严谨 的 风格 提出 观点 进行 论述 论证 尽管 本人 对 物理学 了解 不深 但是 仍然 能 感受 到 真理 的 火花 整本书 的 结构 颇 有 特点 从 当时 本 书写 于 八十年代 流行 的 计算机 话题 引入 再用 数学 物理学 宇宙学 做 必要 的 铺垫 这些 内容 占据 了 大部分 篇幅 最后 回到 关键问题 电脑 能 不能 代替 人脑 和 现在 流行 的 观点 相反 作者 认为 人 的 某种 洞察 是 不能 被 算法 模拟 的 也许 作者 想 说 人 的 灵魂 是 无可取代 的']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#每个词用空格分割\n",
    "corpus[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91789c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'书籍': 0,\n",
       " '平板': 1,\n",
       " '手机': 2,\n",
       " '水果': 3,\n",
       " '洗发水': 4,\n",
       " '热水器': 5,\n",
       " '蒙牛': 6,\n",
       " '衣服': 7,\n",
       " '计算机': 8,\n",
       " '酒店': 9}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构建类别与编号的转换字典，并将类别转成编号\n",
    "class2idx ={'书籍':0, '平板':1, '手机':2, '水果':3, '洗发水':4, '热水器':5, '蒙牛':6, '衣服':7, '计算机':8, '酒店':9}\n",
    "idx2class = {idx:class_ for class_,idx in class2idx.items()}\n",
    "class_idx =[class2idx[calss_] for calss_ in df['cat'].values]\n",
    "class2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bda26d",
   "metadata": {},
   "source": [
    "## TF-IDF和Bag-of-words实现向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2d83243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn实现TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vec=TfidfVectorizer(max_features=1000)\n",
    "tfidf_matrix=tfidf_vec.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd99ebfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn实现bagofword\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "tfidf_matrix1 = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39281bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分训练集验证集\n",
    "train_x1, valid_x1, train_y1, valid_y1 = train_test_split(tfidf_matrix, class_idx, random_state=22,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a8d374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分训练集验证集\n",
    "train_x2, valid_x2, train_y2, valid_y2 = train_test_split(tfidf_matrix1, class_idx, random_state=22,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69320266",
   "metadata": {},
   "source": [
    "## 使用SVM实现网购评论的对象分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2b40ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义SVM分类器并进行分类，评价指标设为准确率，召回率和F1值\n",
    "def SVM(train_x,train_y,valid_x,valid_y):\n",
    "    svm = SVC(max_iter=500)\n",
    "    svm.fit(train_x, train_y)\n",
    "    val_pred = svm.predict(valid_x)\n",
    "    f1 = f1_score(valid_y, val_pred, average='macro')\n",
    "    Accuracy_score = accuracy_score(valid_y, val_pred)\n",
    "    Recall_score = recall_score(valid_y, val_pred,average='macro')\n",
    "    print(f'Accuracy_score:{Accuracy_score}')\n",
    "    print(f'Recall_score:{Recall_score}')\n",
    "    print(f'f1_score:{f1}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25cbab12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\bd\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score:0.7315833333333334\n",
      "Recall_score:0.7237494564062985\n",
      "f1_score:0.7507279936063987\n"
     ]
    }
   ],
   "source": [
    "#使用SVM分类器并进行分类(TF-IDF）\n",
    "SVM(train_x1,train_y1, valid_x1, valid_y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18c72a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\bd\\lib\\site-packages\\sklearn\\svm\\_base.py:289: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  ConvergenceWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score:0.6163333333333333\n",
      "Recall_score:0.6450487458510076\n",
      "f1_score:0.6550754410041175\n"
     ]
    }
   ],
   "source": [
    "#使用SVM分类器并进行分类(Bag-of-words）\n",
    "SVM(train_x2,train_y2, valid_x2, valid_y2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
